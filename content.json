{"meta":{"title":"Funky's Blog","subtitle":"Quick Notes","description":null,"author":"Funky Gao","url":"http://funkygao.github.io"},"pages":[{"title":"tags","date":"2017-05-15T23:20:30.000Z","updated":"2017-05-19T00:26:43.000Z","comments":true,"path":"tags/index.html","permalink":"http://funkygao.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Cassandra","slug":"Cassandra","date":"2017-05-31T00:16:23.000Z","updated":"2017-05-31T02:45:16.000Z","comments":true,"path":"2017/05/31/Cassandra/","link":"","permalink":"http://funkygao.github.io/2017/05/31/Cassandra/","excerpt":"","keywords":[],"text":"CassandraFeatures CQL(Cassandra Query Language) 1,000 node clusters multi-data center out-of-the-box replication ecosystem with Spark Internals LSM Tree Gossip P2P DHT consistency learned from Dynamo ONE QUONUM ALL read repair Thrift ScyllaDBKVM核心人员用C++写的Cassandra(Java) clone，单机性能提高了10倍，主要原因是： DPDK, bypass kernel O_DIRECT IO, bypass pagecache, cache由scylla自己管理 pagecahce的格式必须是文件的格式(sstable)，而app level cache更有效，更terse compaction的时候，pagecache讲是个累赘，它可能造成很多热点数据的淘汰 把一个node看做是多个cpu core组成的cluster, share nothing sharding at the cpu core instead of node更充分利用多核，减少contention，充分利用cpu cache, NUMA friendly 在需要core间交换数据时，使用explicit messaging avoid JVM GC Referenceshttps://db-engines.com/en/rankinghttps://github.com/scylladb/scyllahttp://www.scylladb.com/https://www.reddit.com/r/programming/comments/3lzz56/scylladb_cassandra_rewritten_in_c_claims_to_be_up/https://news.ycombinator.com/item?id=10262719","categories":[],"tags":[{"name":"storage","slug":"storage","permalink":"http://funkygao.github.io/tags/storage/"}]},{"title":"etcd3 vs zookeeper","slug":"etcd3-vs-zookeeper","date":"2017-05-25T09:07:34.000Z","updated":"2017-05-26T07:49:59.000Z","comments":true,"path":"2017/05/25/etcd3-vs-zookeeper/","link":"","permalink":"http://funkygao.github.io/2017/05/25/etcd3-vs-zookeeper/","excerpt":"","keywords":[],"text":"etcd v3独有的特性 get and watch by prefix, by interval lease based TTL for key sets 获取历史版本数据(这个非常有用) watcher功能丰富 支持index参数，不会lose event streaming recursive zk独有的特性 ephemeral znode","categories":[],"tags":[{"name":"一致性","slug":"一致性","permalink":"http://funkygao.github.io/tags/一致性/"}]},{"title":"2017 kafka report","slug":"2017-kafka-report","date":"2017-05-25T01:30:27.000Z","updated":"2017-05-25T01:54:10.000Z","comments":true,"path":"2017/05/25/2017-kafka-report/","link":"","permalink":"http://funkygao.github.io/2017/05/25/2017-kafka-report/","excerpt":"","keywords":[],"text":"调查来自47个国家的388个组织(公司)26%受访者年销售额10亿美金以上15%受访者每天处理10亿消息/天43%受访者在公有云上使用kafka，其中60%是AWS Referenceshttps://www.confluent.io/wp-content/uploads/2017-Apache-Kafka-Report.pdf","categories":[],"tags":[{"name":"PubSub","slug":"PubSub","permalink":"http://funkygao.github.io/tags/PubSub/"}]},{"title":"zookeeper processor","slug":"zookeeper-processor","date":"2017-05-25T00:39:35.000Z","updated":"2017-05-26T07:11:03.000Z","comments":true,"path":"2017/05/25/zookeeper-processor/","link":"","permalink":"http://funkygao.github.io/2017/05/25/zookeeper-processor/","excerpt":"","keywords":[],"text":"Chain of Responsibility为了实现各种服务器的代码结构的高度统一，不同角色的server对应不同的processor chain 123interface RequestProcessor &#123; void processRequest(Request request) throws RequestProcessorException;&#125; LeaderZooKeeperServer.java FollowerZooKeeperServer.java ZooKeeperServer.java1234567func processPacket() &#123; submitRequest()&#125;func submitRequest(req) &#123; firstProcessor.processRequest(req)&#125;","categories":[],"tags":[{"name":"一致性","slug":"一致性","permalink":"http://funkygao.github.io/tags/一致性/"}]},{"title":"kafka redesign","slug":"kafka-redesign","date":"2017-05-24T02:21:06.000Z","updated":"2017-05-24T08:15:10.000Z","comments":true,"path":"2017/05/24/kafka-redesign/","link":"","permalink":"http://funkygao.github.io/2017/05/24/kafka-redesign/","excerpt":"","keywords":[],"text":"Goals support many topics needle in haystack IO optimization R/W isolation index file leads to random sync write","categories":[],"tags":[{"name":"PubSub","slug":"PubSub","permalink":"http://funkygao.github.io/tags/PubSub/"}]},{"title":"apache bookeeper","slug":"apache-bookeeper","date":"2017-05-23T09:04:32.000Z","updated":"2017-05-24T08:13:14.000Z","comments":true,"path":"2017/05/23/apache-bookeeper/","link":"","permalink":"http://funkygao.github.io/2017/05/23/apache-bookeeper/","excerpt":"","keywords":[],"text":"Features 没有topic/partition概念，一个stream是由多个ledger组成的，每个ledger是有边界的createLedger(int ensSize, int writeQuorumSize, int ackQuorumSize) ledger只有int id，没有名字 每个entry(log)是有unique int64 id的 striped write: 交错存储 各个存储节点bookie之间没有明确的主从关系 shared WAL single writer Quorum投票复制，通过存储在zk里的LastAddConfirmedId确保read consistency bookie does not communicate with other bookies，由client进行并发broadcast/quorum VS Kafka createLedger时，客户端决定如何placement(org.apache.bookkeeper.client.EnsemblePlacementPolicy)，然后存放在zookeeper例如，5个bookie，createLedger(3, 3, 2) IO Model 读写分离 Disk 1: Journal(WAL) Device {timestamp}.txn Disk 2: Ledger Device 数据存放在多个ledger目录 LastLogMark表示index+data在此之前的都已经持久化到了Ledger Device，之前的WAL可以删除 异步写 而且是顺序写 所有的active ledger共用一个entry logger 读的时候利用ledger index/cache [Disk 3]: Index Device 默认Disk2和Disk3是在一起的 在写入Memtable后，就可以向client ack了 IO被分成4种类型，分别优化 sync sequential write: shared WAL async random write: group commit from Memtable tail read: from Memtable random read: from (index + os pagecache) Referenceshttps://github.com/ivankelly/bookkeeper-tutorialhttps://github.com/twitter/DistributedLog","categories":[],"tags":[{"name":"PubSub","slug":"PubSub","permalink":"http://funkygao.github.io/tags/PubSub/"}]},{"title":"SSD","slug":"SSD","date":"2017-05-22T06:31:39.000Z","updated":"2017-05-22T06:31:50.000Z","comments":true,"path":"2017/05/22/SSD/","link":"","permalink":"http://funkygao.github.io/2017/05/22/SSD/","excerpt":"","keywords":[],"text":"http://codecapsule.com/2014/02/12/coding-for-ssds-part-6-a-summary-what-every-programmer-should-know-about-solid-state-drives/","categories":[],"tags":[{"name":"storage","slug":"storage","permalink":"http://funkygao.github.io/tags/storage/"}]},{"title":"oklog","slug":"oklog","date":"2017-05-22T03:22:58.000Z","updated":"2017-05-23T01:35:42.000Z","comments":true,"path":"2017/05/22/oklog/","link":"","permalink":"http://funkygao.github.io/2017/05/22/oklog/","excerpt":"","keywords":[],"text":"injecter负责write优化(WAL)，让storage node负责read优化与RocketMQ类似: CQRS injecter = commit log storage node = consume log 不同在于：storage node是通过pull mode replication机制实现，可以与injecter位于不同机器而RocketMQ的commit log与consume log是在同一台broker上的 kafka couples R/W，无法独立scale CQRS decouples R/W，可以独立scale produceProducer通过forwarder连接到多个injecter上，injecter间通过gossip来负载均衡，load高的会通过与forwarder协商进行redirect distribution queryscatter-gather","categories":[],"tags":[{"name":"PubSub","slug":"PubSub","permalink":"http://funkygao.github.io/tags/PubSub/"}]},{"title":"db trigger","slug":"db-trigger","date":"2017-05-22T02:40:14.000Z","updated":"2017-05-22T02:50:00.000Z","comments":true,"path":"2017/05/22/db-trigger/","link":"","permalink":"http://funkygao.github.io/2017/05/22/db-trigger/","excerpt":"","keywords":[],"text":"触发器的缺陷 如何监控 代码的版本控制 test 部署 性能损耗 多租户 资源隔离 无法频繁发布，如何应付频繁的需求变更","categories":[],"tags":[{"name":"database","slug":"database","permalink":"http://funkygao.github.io/tags/database/"}]},{"title":"materialized view","slug":"materialized-view","date":"2017-05-22T02:05:02.000Z","updated":"2017-05-22T02:57:51.000Z","comments":true,"path":"2017/05/22/materialized-view/","link":"","permalink":"http://funkygao.github.io/2017/05/22/materialized-view/","excerpt":"","keywords":[],"text":"物化试图，可以理解为cache of query results, derived result觉得用“异构表”可能更贴切 与试图不同，它是物理存在的，并由数据库来确保与主库的一致性它是随时可以rebuilt from source store，应用是从来不会更新它的: readonly MySQL没有提供该功能，但通过dbus可以方便构造materialized viewPostgreSQL提供了materialized view Referenceshttps://docs.microsoft.com/en-us/azure/architecture/patterns/materialized-view","categories":[],"tags":[{"name":"database","slug":"database","permalink":"http://funkygao.github.io/tags/database/"}]},{"title":"cache invalidation","slug":"cache-invalidation","date":"2017-05-22T01:52:37.000Z","updated":"2017-05-22T02:59:27.000Z","comments":true,"path":"2017/05/22/cache-invalidation/","link":"","permalink":"http://funkygao.github.io/2017/05/22/cache-invalidation/","excerpt":"","keywords":[],"text":"1234567891011// read dataval = cache.get(key)if val == nil &#123; val = db.get(key) cache.put(key, val)&#125;return val// write datadb.put(key, val)cache.put(key, val) 这会造成dual write conflict 如果需要的只是eventaul consistency，那么通过dbus来进行cache invalidation是最有效的 https://martinfowler.com/bliki/TwoHardThings.html","categories":[],"tags":[{"name":"一致性","slug":"一致性","permalink":"http://funkygao.github.io/tags/一致性/"}]},{"title":"Linked Esprosso","slug":"Linked-Esprosso","date":"2017-05-22T00:07:48.000Z","updated":"2017-05-23T01:50:05.000Z","comments":true,"path":"2017/05/22/Linked-Esprosso/","link":"","permalink":"http://funkygao.github.io/2017/05/22/Linked-Esprosso/","excerpt":"","keywords":[],"text":"WhatDistributed Document Store RESTful API MySQL作为存储 Helix负责集群 Databus异步replicate不同数据中心commit log Schema存放在zookeeper，通过Avro的兼容性实现schema evolution Referenceshttps://engineering.linkedin.com/espresso/introducing-espresso-linkedins-hot-new-distributed-document-store https://nonprofit.linkedin.com/content/dam/static-sites/thirdPartyJS/github-gists?e_origin=https://engineering.linkedin.com&amp;e_channel=resource-iframe-embed-4","categories":[],"tags":[{"name":"database","slug":"database","permalink":"http://funkygao.github.io/tags/database/"}]},{"title":"Multi-Data Center Consistency","slug":"Multi-Data-Center-Consistency","date":"2017-05-19T07:18:33.000Z","updated":"2017-05-19T08:09:06.000Z","comments":true,"path":"2017/05/19/Multi-Data-Center-Consistency/","link":"","permalink":"http://funkygao.github.io/2017/05/19/Multi-Data-Center-Consistency/","excerpt":"","keywords":[],"text":"MDCC提供了跨机房的分布式数据库强一致性模型 Referenceshttp://mdcc.cs.berkeley.edu/","categories":[],"tags":[{"name":"一致性","slug":"一致性","permalink":"http://funkygao.github.io/tags/一致性/"}]},{"title":"asynchronous distributed snapshot","slug":"distributed-snapshot","date":"2017-05-19T02:32:48.000Z","updated":"2017-05-19T09:31:46.000Z","comments":true,"path":"2017/05/19/distributed-snapshot/","link":"","permalink":"http://funkygao.github.io/2017/05/19/distributed-snapshot/","excerpt":"","keywords":[],"text":"如何给分布式系统做个全局逻辑一致的快照?Node State + Channel State 发送规则12345node.recordState()for conn in allConns &#123; // before any conn&apos;s outbound msg conn.send(marker)&#125; 接收规则123456789101112msg = conn.recv()if msg.isMarker() &#123; t1 = now() if !node.stateRecorded() &#123; node.recordState() Channel(conn) = [] &#125; else &#123; Channel(conn) = msgsBetween(now(), t1) // in-flight msgs not applied on state node.state.apply(msgs before the marker) &#125;&#125; Demo 12345678910111213141516171819202122232425a)P为自己做快照P(red, green, blue)在Channel(PQ)上 send(marker)b)P把绿球送给Q，这个消息是在marker后面以此同时，Q把自己的橙色球送给P，此时Q(brown, pink)c) Q在Channel(PQ)上收到marker // Q是接收者Q为自己做快照Q(brown, pink)Channel(PQ) = []// 因为之前Q把自己的橙色球送给了P，因此Q也是发送者在Channel(QP)上 send(marker)d)P收到橙色球，然后是marker由于P已经记录了state, Channel(QP)=[orange, ]最终的分布式系统的snapshot:P(red, green, blue)Channel(PQ) []Q(brown, pink)Channel(QP) = [orange, ] FAQ如何发起发起global distributed snapshot的节点，可以是一台，也可以多台并发 如何结束所有节点上都完成了snapshot 用途故障恢复 与Apache Storm的基于记录的ack不同，Apache Flink的failure recovery采用了改进的Chandy-Lamport算法checkpoint coordinator是JobManager data sources periodically inject markers into the data stream.123val env = StreamExecutionEnvironment.getExecutionEnvironmentenv.setParallelism(4)env.enableCheckpointing(1000) // 数据源每1s发送marker(barrier) Whenever an operator receives such a marker, it checkpoints its internal state.1234567891011121314151617181920212223242526272829303132class StateMachineMapper extends FlatMapFunction[Event, Alert] with Checkpointed[mutable.HashMap[Int, State]] &#123; private[this] val states = new mutable.HashMap[Int, State]() override def flatMap(t: Event, out: Collector[Alert]): Unit = &#123; // get and remove the current state val state = states.remove(t.sourceAddress).getOrElse(InitialState) val nextState = state.transition(t.event) if (nextState == InvalidTransition) &#123; // 报警 out.collect(Alert(t.sourceAddress, state, t.event)) &#125; else if (!nextState.terminal) &#123; // put back to states states.put(t.sourceAddress, nextState) &#125; &#125; override def snapshotState(checkpointId: Long, timestamp: Long): mutable.HashMap[Int, State] = &#123; // barrier(marker) injected from data source and flows with the records as part of the data stream // // snapshotState()与flatMap()一定是串行执行的 // 此时operator已经收到了barrier(marker) // 在本方法返回后，flink会自动把barrier发给我的output streams // 再然后，保存states(默认是JobManager内存，也可以HDFS) states &#125; override def restoreState(state: mutable.HashMap[Int, State]): Unit = &#123; // 出现故障后，flink会停止dataflow，然后重启operator(StateMachineMapper) states ++= state &#125;&#125; Referenceshttp://research.microsoft.com/en-us/um/people/lamport/pubs/chandy.pdfhttps://arxiv.org/abs/1506.08603https://ci.apache.org/projects/flink/flink-docs-master/internals/stream_checkpointing.htmlhttps://github.com/StephanEwen/flink-demos/tree/master/streaming-state-machine","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"http://funkygao.github.io/tags/algorithm/"}]},{"title":"https","slug":"https","date":"2017-05-19T00:21:27.000Z","updated":"2017-05-19T00:24:17.000Z","comments":true,"path":"2017/05/19/https/","link":"","permalink":"http://funkygao.github.io/2017/05/19/https/","excerpt":"","keywords":[],"text":"curl https://baidu.comHow the 270ms passed1234567891011121314151617181920212223242526272829303132333435363738394041424344451 1 0.0721 (0.0721) C&gt;S Handshake ClientHello Version 3.1 cipher suites TLS_EMPTY_RENEGOTIATION_INFO_SCSV TLS_DHE_RSA_WITH_AES_256_CBC_SHA TLS_DHE_RSA_WITH_AES_256_CBC_SHA256 TLS_DHE_DSS_WITH_AES_256_CBC_SHA TLS_RSA_WITH_AES_256_CBC_SHA TLS_RSA_WITH_AES_256_CBC_SHA256 TLS_DHE_RSA_WITH_AES_128_CBC_SHA TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 TLS_DHE_DSS_WITH_AES_128_CBC_SHA TLS_RSA_WITH_RC4_128_SHA TLS_RSA_WITH_RC4_128_MD5 TLS_RSA_WITH_AES_128_CBC_SHA TLS_RSA_WITH_AES_128_CBC_SHA256 TLS_DHE_RSA_WITH_3DES_EDE_CBC_SHA TLS_DHE_DSS_WITH_3DES_EDE_CBC_SHA TLS_RSA_WITH_3DES_EDE_CBC_SHA compression methods NULL1 2 0.1202 (0.0480) S&gt;C Handshake ServerHello Version 3.1 session_id[32]= b3 ea 99 ee 5a 4c 03 e8 e0 74 95 09 f1 11 09 2a 9d f5 8f 2a 26 7a d3 7f 71 ff dc 39 62 66 b0 f9 cipherSuite TLS_RSA_WITH_AES_128_CBC_SHA compressionMethod NULL1 3 0.1205 (0.0002) S&gt;C Handshake Certificate1 4 0.1205 (0.0000) S&gt;C Handshake ServerHelloDone1 5 0.1244 (0.0039) C&gt;S Handshake ClientKeyExchange1 6 0.1244 (0.0000) C&gt;S ChangeCipherSpec1 7 0.1244 (0.0000) C&gt;S Handshake1 8 0.1737 (0.0492) S&gt;C ChangeCipherSpec1 9 0.1737 (0.0000) S&gt;C Handshake1 10 0.1738 (0.0001) C&gt;S application_data1 11 0.2232 (0.0493) S&gt;C application_data1 12 0.2233 (0.0001) C&gt;S Alert1 0.2234 (0.0000) C&gt;S TCP FIN1 0.2709 (0.0475) S&gt;C TCP FIN","categories":[],"tags":[{"name":"ops","slug":"ops","permalink":"http://funkygao.github.io/tags/ops/"}]},{"title":"hybrid logical clock","slug":"hlc","date":"2017-05-18T23:51:28.000Z","updated":"2017-05-27T00:07:48.000Z","comments":true,"path":"2017/05/19/hlc/","link":"","permalink":"http://funkygao.github.io/2017/05/19/hlc/","excerpt":"","keywords":[],"text":"分布式事务，为了性能，目前通常提供SI/SSI级别的isolation，通过乐观冲突检测而非2PC悲观方式实现，这就要求实现事务的causality，通常都是拿逻辑时钟实现total order例如vector clock就是一种，zab里的zxid也是；google percolator里的total order算是另外一种逻辑时钟，但这种方法由于有明显瓶颈，也增加了一次消息传递 但逻辑时钟无法反应物理时钟，因此有人提出了混合时钟，wall time + logical time，分别是给人看和给机器看，原理比较简单，就是在交互消息时，接收方一定sender event happens before receiver 但wall time本身比较脆弱，例如一个集群，有台机器ntp出现问题，管理员调整时间的时候出现人为错误，本来应该是2017-09-09 10:00:00，结果typo成2071-09-09 10:00:00，后果是它会传染给集群内所有机器，hlc里的wall time都会变成2071年，人工无法修复，除非允许丢弃历史数据，只有等到2071年那一天系统会自动恢复，wall time部分也就失去了意义 要解决这个问题，可以加入epoch1234HLC+-------+-----------+--------------+| epoch | wall time | logical time |+-------+-----------+--------------+ 修复2071问题时，只需把epoch+1","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"http://funkygao.github.io/tags/algorithm/"}]},{"title":"可靠性金字塔","slug":"SRE","date":"2017-05-18T05:55:21.000Z","updated":"2017-05-19T00:13:21.000Z","comments":true,"path":"2017/05/18/SRE/","link":"","permalink":"http://funkygao.github.io/2017/05/18/SRE/","excerpt":"","keywords":[],"text":"","categories":[],"tags":[{"name":"SRE","slug":"SRE","permalink":"http://funkygao.github.io/tags/SRE/"}]},{"title":"MySQL B+ Tree","slug":"MySQL-B-Tree","date":"2017-05-18T01:32:32.000Z","updated":"2017-05-18T01:34:07.000Z","comments":true,"path":"2017/05/18/MySQL-B-Tree/","link":"","permalink":"http://funkygao.github.io/2017/05/18/MySQL-B-Tree/","excerpt":"","keywords":[],"text":"","categories":[],"tags":[{"name":"database","slug":"database","permalink":"http://funkygao.github.io/tags/database/"}]},{"title":"batch insert(mysql)","slug":"batch-insert","date":"2017-05-18T00:46:17.000Z","updated":"2017-05-18T00:58:45.000Z","comments":true,"path":"2017/05/18/batch-insert/","link":"","permalink":"http://funkygao.github.io/2017/05/18/batch-insert/","excerpt":"","keywords":[],"text":"1234567// case1INSERT INTO T(v) VALUES(1), (2), (3), (4), (5)// case2for i=1; i&lt;=5; i++ &#123; INSERT INTO T(v) VALUES(i);&#125; case1和2有什么影响？假设auto_commit 好处 减少与mysql server的交互 减少SQL解析(如果statement则没区别) query cache打开时，只会invalidate cache一次，提高cache hit 坏处 可能变成一个大事务batch insert的时候，batch不能太大","categories":[],"tags":[{"name":"database","slug":"database","permalink":"http://funkygao.github.io/tags/database/"}]},{"title":"cannot have exactly-once delivery","slug":"cannot-have-exactly-once-delivery","date":"2017-05-17T02:46:26.000Z","updated":"2017-05-18T06:12:44.000Z","comments":true,"path":"2017/05/17/cannot-have-exactly-once-delivery/","link":"","permalink":"http://funkygao.github.io/2017/05/17/cannot-have-exactly-once-delivery/","excerpt":"","keywords":[],"text":"http://bravenewgeek.com/you-cannot-have-exactly-once-delivery/","categories":[],"tags":[{"name":"PubSub","slug":"PubSub","permalink":"http://funkygao.github.io/tags/PubSub/"}]},{"title":"RocketMQ解读","slug":"RocketMQ","date":"2017-05-17T02:38:32.000Z","updated":"2017-05-18T00:29:34.000Z","comments":true,"path":"2017/05/17/RocketMQ/","link":"","permalink":"http://funkygao.github.io/2017/05/17/RocketMQ/","excerpt":"","keywords":[],"text":"Features Producer Group发送事务消息时，作为TC，要多机，保存事务状态表{offset: P/C/R} Broker tag-based message filter 定时消息，不支持任意精度，只是特定level: 5s, 10s, 1m等 queueID=delayLevel-1因此，应该不支持message revoke 区分commit log和consume log，有点类似WAL和table关系可以把它们放在不同FS下，但没有更细粒度的增加了一个分发步骤的好处：可以不分发 Commit Log1234$&#123;rocketmq.home&#125;\\store\\commitlog\\$&#123;fileName&#125;fileName[n] = fileName[n-1] + mappedFileSize为了保证mappedFileSize相同，在每个file tail加padding，默认1GB 每条消息12345678QueueOffset针对普通消息，存的是consume log里的offset；如果事务消息，是事务状态表的offset+---------+-------+-----+---------+------+-------------+----------------+----------------+| MsgSize | Magic | CRC | QueueID | Flag | QueueOffset | PhysicalOffset | SysFlag(P/C/R) |+---------+-------+-----+---------+------+-------------+----------------+----------------++--------------+------------------+-----------+---------------+----+------+-------+------+| ProducedTime | ProduderHostPort | StoreTime | StoreHostPort | .. | Body | Topic | Prop |+--------------+------------------+-----------+---------------+----+------+-------+------+ 每次append commit log，会同步调用dispatch分发到consume queue和索引服务1234567new DispatchRequest(topic, queueId, result.getWroteOffset(), result.getWroteBytes(), tagsCode, msg.getStoreTimestamp(), result.getLogicsOffset(), msg.getKeys(), // Transaction msg.getSysFlag(), msg.getPreparedTransactionOffset()); queue仅仅是逻辑概念，可以通过它来参与producer balance，类似一致哈希里的虚拟节点每台broker上的commitlog被本机所有的queue共享，不做任何区分 1234567broker1: queue0, queue2broker2: queue0, then, topicA has 3 queues:broker1_queue0, broker1_queue2, broker2_queue0producer.selectOneMessageQueue(&quot;topicA&quot;, &quot;broker1&quot;, &quot;queue0&quot;) 消息的局部顺序由producer client保证 Question 如何实现retention by topic: 没有实现仅仅根据commit log file的mtime来判断是否过期，虽然里面混杂多topics 如何I/O balancing 如何压缩 如果CRC出错，那么所有topic都受影响? 为什么要存StoreHostPort？如何迁移topic：无法迁移 写commit log需要加锁，这个锁粒度太大，相当于db level lock，而非table level broker的脑裂问题 failover topic的commit log是分散在所有broker上的 Consume Queue1$&#123;rocketmq.home&#125;/store/consumequeue/$&#123;topicName&#125;/$&#123;queueId&#125;/$&#123;fileName&#125; 读一条消息，先读consume queue(类似mysql的secondary index)，再读commit log(clustered index) 没有采用sendfile，而是通过mmap：因为random read 123+---------------------+-----------------+------------------------+| CommitLogOffset(8B) | MessageSize(4B) | MessageTagHashcode(8B) |+---------------------+-----------------+------------------------+ 虽然消费时，consume queue是顺序的，但接下来的commit log几乎都是random read，此外如何优化压缩？光靠pagecache+readahead是远远不够的 Producer123TopicPublishInfo topicPublishInfo = this.tryToFindTopicPublishInfo(msg.getTopic()); // from local cache or name serverMessageQueue mq = topicPublishInfo.selectOneMessageQueue(lastBrokerName);sendResult = this.sendKernelImpl(msg, mq, communicationMode, sendCallback, timeout); Transaction123456789101112131415// 2PC，2 messages// Phase1producer group write redologproducer group send a message(type=TransactionPreparedType) to brokerbroker append it to CommitLog and return MessageIdbroker will not append it to consume queue// Phase2producer group write redologproducer group send a message(type=TransactionCommitType, msgId=$msgId) to brokerbroker find the message with msgId in CommitLog and clone it and append it to CommitLog(type=TransactionCommitType|TransactionRollbackType)if type == TransactionCommitType &#123; broker append commit log offset to consume queue&#125; State Table保存在broker，默认1m扫一次 1234567824B, mmap+-----------------+------+-----------+-----------------------+--------------+| CommitLogOffset | Size | Timestamp | ProducerGroupHashcode | State(P/C/R) |+-----------------+------+-----------+-----------------------+--------------+prepare消息，insert tablecommit/rollback消息，update table 对于未决事务，根据随机向Producer Group里的一台发请求CHECK_TRANSACTION_STATEProducer Group根据redolog(mmap)定位状态Producer Group信息存放在namesvr Problems Producer不再是普通的client，它已经变成server(TC)，而且要求不能随便shutdown Producer Group里写redolog的机器死了怎么办","categories":[],"tags":[{"name":"PubSub","slug":"PubSub","permalink":"http://funkygao.github.io/tags/PubSub/"}]},{"title":"architecture design checklist","slug":"architecture-design-checklist","date":"2017-05-17T01:00:00.000Z","updated":"2017-05-17T01:01:46.000Z","comments":true,"path":"2017/05/17/architecture-design-checklist/","link":"","permalink":"http://funkygao.github.io/2017/05/17/architecture-design-checklist/","excerpt":"","keywords":[],"text":"archeck","categories":[],"tags":[{"name":"tools","slug":"tools","permalink":"http://funkygao.github.io/tags/tools/"}]},{"title":"kateway replay messages","slug":"kateway-replay-messages","date":"2017-05-16T23:52:34.000Z","updated":"2017-05-17T00:27:21.000Z","comments":true,"path":"2017/05/17/kateway-replay-messages/","link":"","permalink":"http://funkygao.github.io/2017/05/17/kateway-replay-messages/","excerpt":"","keywords":[],"text":"Issueconsumer有需求回放/快进消息，目前kateway具有该功能：用户在web console上把offset设置到指定位置 但由于机器里kateway正在消费源源不断的消息，checkpoint会overwrite这个指定的offset这就要求用户先关闭消费进程，然后web console上操作，再启动消费进程: not user friendly在不影响性能前提下，对其进行改进 Solution12345678910111213141516171819202122232425_, stat, err := cg.kz.conn.Get(path)if cg.lastVer == -1 &#123; // 第一次commit offset cg.lastVer = stat.Version&#125; else if cg.lastVer != stat.Version &#123; // user manually reset the offset checkpoint return ErrRestartConsumerGroup&#125;// 也可能在Get后，用户恰好操作了“回放”，通过CAS解决这个问题switch err &#123;case zk.ErrNoNode: return cg.kz.create(path, data, false)case nil: newStat, err := cg.kz.conn.Set(path, data, stat.Version) if err != nil &#123; cg.lastVer = newStat.Version &#125; return errdefault: return err&#125;","categories":[],"tags":[{"name":"PubSub","slug":"PubSub","permalink":"http://funkygao.github.io/tags/PubSub/"}]},{"title":"how DBMS works","slug":"how-DBMS-works","date":"2017-05-16T08:31:29.000Z","updated":"2017-05-16T08:37:01.000Z","comments":true,"path":"2017/05/16/how-DBMS-works/","link":"","permalink":"http://funkygao.github.io/2017/05/16/how-DBMS-works/","excerpt":"","keywords":[],"text":"Undo log Oracle和MySQL机制类似 MS SQL Server里，称为transaction log PostgreSQL里没有undo log，它通过mvcc系统表实现，每一行存储多个版本 Redo log Oracle和MySQL机制类似 MS SQL Server里，称为transaction log PostgreSQL里称为WAL","categories":[],"tags":[{"name":"database","slug":"database","permalink":"http://funkygao.github.io/tags/database/"}]},{"title":"scalability papers","slug":"scalability-papers","date":"2017-05-16T08:28:29.000Z","updated":"2017-05-16T08:28:47.000Z","comments":true,"path":"2017/05/16/scalability-papers/","link":"","permalink":"http://funkygao.github.io/2017/05/16/scalability-papers/","excerpt":"","keywords":[],"text":"http://www.perfdynamics.com/Manifesto/USLscalability.html","categories":[],"tags":[{"name":"scalability","slug":"scalability","permalink":"http://funkygao.github.io/tags/scalability/"}]},{"title":"PostgreSQL MVCC","slug":"PostgreSQL-MVCC","date":"2017-05-16T03:54:13.000Z","updated":"2017-05-16T08:23:45.000Z","comments":true,"path":"2017/05/16/PostgreSQL-MVCC/","link":"","permalink":"http://funkygao.github.io/2017/05/16/PostgreSQL-MVCC/","excerpt":"","keywords":[],"text":"InternalsMySQL通过undo log记录uncommitted changes，与此不同，PostgreSQL store all row versions in table data structure. 每个row有2个隐藏字段 Tmin insert时的trx id Tmax delete时的trx id INSERT DELETE DELETE操作并不会马上物理删除，而是VACUUM进程调度进行purge UPDATE","categories":[],"tags":[{"name":"database","slug":"database","permalink":"http://funkygao.github.io/tags/database/"}]},{"title":"VNC protocol","slug":"VNC-protocol","date":"2017-05-16T02:32:46.000Z","updated":"2017-05-17T00:51:09.000Z","comments":true,"path":"2017/05/16/VNC-protocol/","link":"","permalink":"http://funkygao.github.io/2017/05/16/VNC-protocol/","excerpt":"","keywords":[],"text":"WebRTCWebRTC提供了direct data and media stream transfer between two browsers without external server involved: P2P 浏览器上点击“Screen share”按钮后 12345678// sender利用OS的API获取screenshot，并以一定的FPS来进行发送// 优化：把屏幕分成chunk，在把timer之间有变化的chunk生成frame发送时，frame被编码成H.264或VP8通过HTTPS发送// receiver对接收到的frame解码并显示 通过WebRTC实现的是只读的屏幕分享，receiver不能控制sender屏幕 实现123456789101112131415161718192021222324252627&lt;body&gt; &lt;p&gt;&lt;input type=&quot;button&quot; id=&quot;share&quot; value=&quot;Screen share&quot; /&gt;&lt;/p&gt; &lt;p&gt;&lt;video id=&quot;video&quot; autoplay /&gt;&lt;/p&gt;&lt;/body&gt;&lt;script&gt;navigator.getUserMedia = navigator.webkitGetUserMedia || navigator.getUserMedia;$(&apos;#share&apos;).click(function() &#123; navigator.getUserMedia(&#123; audio: false , video: &#123; mandatory: &#123; chromeMediaSource: &apos;screen&apos; , maxWidth: 1280 , maxHeight: 720 &#125; , optional: [ ] &#125; &#125;, function(stream) &#123; // we&apos;ve got media stream // so the received stream can be transmitted via WebRTC the same way as web camera and easily played in &lt;video&gt; component on the other side document.getElementById(&apos;video&apos;).src = window.URL.createObjectURL(stream); &#125; , function() &#123; alert(&apos;Error. Try in latest Chrome with Screen sharing enabled in about:flags.&apos;); &#125;)&#125;)&lt;/script&gt; VNCRemote Frame Buffer，支持X11, Windows, Mac远程终端用户使用机器（比如显示器、键盘、鼠标）的叫做客户端，提供帧缓存变化的被称为服务器 显示协议pixel(x, y) =&gt; 像素数据编码 C-&gt;S消息类型SetEncodingsRaw, CopyRect, RRE, Hextile, TRLE, ZRLE FramebufferUpdateRequest最重要的显示消息，表示client要server传回哪些区域的图像 1234client.send(messageType, incremental, x, y, width, height) =&gt; server// incremental&gt;0，表示该区域内容变化了才发给client；没有变化，就不用发server.reply(messageType, rectangleN, [&#123;x, y, with, height, color&#125;, ...]) =&gt; client KeyEventclient端的键盘动作 PointerEventclient端的鼠标动作 vnc browserhttp://guacamole.incubator.apache.org/https://github.com/novnc/noVNC Referenceshttp://www.tuicool.com/articles/Rzqumuhttps://github.com/macton/htermchrome://flags/#enable-usermedia-screen-capture","categories":[],"tags":[{"name":"protocol","slug":"protocol","permalink":"http://funkygao.github.io/tags/protocol/"}]},{"title":"LSM for SSD","slug":"LSM","date":"2017-05-16T01:33:59.000Z","updated":"2017-05-16T09:55:36.000Z","comments":true,"path":"2017/05/16/LSM/","link":"","permalink":"http://funkygao.github.io/2017/05/16/LSM/","excerpt":"","keywords":[],"text":"Basics (immutable)memtable: sorted skiplist SSTable: sorted string table L0里的SSTable们，key可能会overlap，因为他们是直接从immutable memtable刷出来的 SSTable file123+-------------------+-------------------------+------------+| index block(16KB) | bloom-filter block(4KB) | data block |+-------------------+-------------------------+------------+ Get(key)12345678910111213locate key in memtableif found then returnlocate key in immutable memtableif found then returnfor level:=0; level&lt;=6; level++ &#123; // 对于level0，需要遍历所有SSTable，因为keys overlap // 但leveldb为了解决这个问题，除了Bloomfilter，也限制了L0的文件数量，一旦超过8，就compact(L0-&gt;L1) // 对于其他level，由于已经sorted，可以直接定位SSTable // // 最坏情况下，Get(key)需要读8个L0以及L1-L6，共14个文件 locate key in SSTable in $level if found then return&#125; SSD主流SSD，例如Samsung 960 Pro，可以提供440K/s random readwith block size=4KB LSM是为传统硬盘设计的，在SSD下，可以做优化 优化LSM-Tree的主要成本都在compaction(merge sort)，造成IO放大(50倍) 读很多文件到内存 排序 再写回到磁盘 要优化compaction，可以把LSM Tree变小，RocksDB是通过压缩实现的 在SSD下，可以考虑把key和value分离，在LSM Tree里只保存sorted key和pointer(value)，value直接保存在WAL里 key: 16Bpointer(value): 16B 2M个k/v，需要64MB2B个k/v，需要64GB Referencehttps://www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf","categories":[],"tags":[{"name":"storage","slug":"storage","permalink":"http://funkygao.github.io/tags/storage/"}]},{"title":"InnoDB MVCC","slug":"InnoDB-MVCC","date":"2017-05-16T00:17:17.000Z","updated":"2017-05-16T01:28:27.000Z","comments":true,"path":"2017/05/16/InnoDB-MVCC/","link":"","permalink":"http://funkygao.github.io/2017/05/16/InnoDB-MVCC/","excerpt":"","keywords":[],"text":"BasicInnoDB中通过Undo log实现了txn rollback和MVCC，而并发控制(isolation)通过锁来实现Undo log分为insert undo和update undo(delete是一种特殊的update)，回滚时 insert只要把insert undo log丢弃即可 update需要通过DB_ROLL_PTR DB_TRX_ID找到事务修改前的版本并恢复 与redo log不同的是，磁盘上不存在单独的undo log文件，所有的undo log均存放在主ibd数据文件中（表空间），即使客户端设置了每表一个数据文件也是如此 内部存储InnoDB为每行row都reserved了隐藏字段(system column) DB_ROW_ID DB_TRX_ID DB_ROLL_PTR 12345typedef ib_uint64_t ib_id_t;typedef ib_id_t row_id_t;typedef ib_id_t trx_id_t;typedef ib_id_t roll_ptr_t; Undo log实现方式 事务以排他锁的形式修改原始数据 把修改前的数据存放于undo log，通过回滚指针与主数据关联 修改成功（commit）啥都不做，失败则恢复undo log中的数据（rollback） Demo Innodb中存在purge线程，它会查询那些比现在最老的活动事务还早的undo log，并删除它们 Issues回滚成本当事务正常提交时Innbod只需要更改事务状态为COMMIT即可，不需做其他额外的工作而Rollback如果事务影响的行非常多，回滚则可能成本很高 write skewInnoDB通过Undo log实现的MVCC在修改单行记录是没有问题的，但多行时就可能出问题1234begin;update table set col1=2 where id=1; // 成功，创建了undo logupdate table set col2=3 where id=2; // 失败rollback; 回滚row(id=1)时，由于它没有被lock，此时可能已经被另外一个txn给修改了，这个回滚会破坏已经commit的事务 如果要解决这个问题，需要应用层进行控制 锁RR隔离级别下，普通select不加锁，使用MVCC进行一致性读取，即snapshot readupdate, insert, delete, select … for update, select … lock in share mode都会进行加锁，并且读取的是当前版本: READ COMMITTED读除了lock in share mode是S锁，其他都是X锁 Referenceshttps://dev.mysql.com/doc/refman/5.7/en/innodb-locks-set.html","categories":[],"tags":[{"name":"database","slug":"database","permalink":"http://funkygao.github.io/tags/database/"}]},{"title":"microservice transaction","slug":"microservice-transaction","date":"2017-05-15T23:02:29.000Z","updated":"2017-05-16T02:27:33.000Z","comments":true,"path":"2017/05/16/microservice-transaction/","link":"","permalink":"http://funkygao.github.io/2017/05/16/microservice-transaction/","excerpt":"","keywords":[],"text":"Referenceshttps://docs.microsoft.com/en-us/azure/architecture/patterns/compensating-transaction","categories":[],"tags":[{"name":"一致性","slug":"一致性","permalink":"http://funkygao.github.io/tags/一致性/"}]},{"title":"zookeeper internals","slug":"zookeeper","date":"2017-05-15T02:26:14.000Z","updated":"2017-05-26T03:24:02.000Z","comments":true,"path":"2017/05/15/zookeeper/","link":"","permalink":"http://funkygao.github.io/2017/05/15/zookeeper/","excerpt":"","keywords":[],"text":"BasicsModelFile api without partial R/WNo rename operation zab通过TCP+zxid实现事务的totally order ImplementationZKDatabase1234567// zk的内存数据库class ZKDatabase &#123; DataTree dataTree LinkedList&lt;Proposal&gt; committedLog FileTxnSnapLog snapLog ConcurrentHashMap&lt;Long, Integer&gt; sessionsWithTimeouts // &#123;sessionID: timeout&#125;&#125; DataTree12345678910111213141516171819202122class DataTree &#123; ConcurrentHashMap&lt;String, DataNode&gt; nodes // &#123;path: znode&#125;, flat ConcurrentHashMap&lt;Long, HashSet&lt;String&gt;&gt; ephemerals // &#123;sessionID: [path, ]&#125; WatchManager dataWatches, childWatches func createNode(path, data) &#123; parent = nodes.get(parentPath) parent.Lock() // check NodeExistsException // set stat of the new znode and its parent child = new DataNode(parent, data, stat) // the new znode parent.addChild(child) nodes.put(path, child) if ephemeralOwner != nil &#123; ephemerals.get(ephemeralOwner).add(path) &#125; parent.Unlock() dataWatches.triggerWatch(path, NodeCreated) childWatches.triggerWatch(parentPath, NodeChildrenChanged) &#125;&#125; DataNode1234567class DataNode &#123; DataNode parent Set&lt;String&gt; children StatPersisted stat []byte data&#125; n(n-1)/2 conns只允许id比较大的server发起主动连接：由于任意server在启动时都会主动向其他server发起连接，如果这样，任意两台server之间就拥有两条连接，这明显是没有必要的123456789======= ======= ======= ======= ======= ========sid 1 2 3 4 5======= ======= ======= ======= ======= ========1 &lt;&gt; &lt; &lt; &lt; &lt;2 &lt;&gt; &lt; &lt; &lt;3 &lt;&gt; &lt; &lt;4 &lt;&gt; &lt;5 &lt;&gt;======= ======= ======= ======= ======= ======== 成为 leader 的条件 选epoch最大的 epoch相等，选 zxid 最大的 epoch和zxid都相等，选择server id最大的 1234(newEpoch &gt; curEpoch) || ((newEpoch == curEpoch) &amp;&amp; ((newZxid &gt; curZxid) || ((newZxid == curZxid) &amp;&amp; (newId &gt; curId)))) 何时选举进入LOOKING状态 刚启动时 稳定运行中，任何的异常都会让本机进入LOOKING态123catch (Exception e) &#123; setPeerState(LOOKING)&#125; ConstraintsMany ZooKeeper write requests are conditional in nature: a znode can only be deleted if it does not have any children a znode can be created with a name and a sequence number appended to it a change to data will only be applied if it is at an expected version Quorum1234567891011121314func isQuorum(type) &#123; // zk的请求有2种 1. 事务请求 2. 只读请求 switch (type) &#123; case OpCode.exists, getACL, getChildren, getChildren2, getData: // 本地执行，不需要proposal return false case OpCode.error, closeSession, create, createSession, delete, setACL, setData, check, multi: return true default: return false &#125;&#125; 注意：session部分，也会走txn multi是原子操作，multi里的每个op都使用相同的zxid WatchWatches are maintained locally at the ZooKeeper server to which the client is connected.它是不走proposal quorum的 Watcher只会告诉客户端发生了什么类型的事件，而不会说明事件的具体内容例如，NodeDataChanged，watcher只会通知client：在你watch的path上，发生了NodeDataChanged这个事件但最新的数据是什么，不在event里，而需要client主动重新去get Watch的通知，由WatchManager完成，它先从内存里删除这个watcher，然后回调watcher.process后者在NIOServerCnxn 1234567891011121314151617181920212223class WatchManager &#123; HashMap&lt;String, HashSet&lt;Watcher&gt;&gt; watchTable func triggerWatch(path, event) &#123; synchronized(this) &#123; watchers = watchTable.remove(path) // so one time trigger &#125; // Watch机制本身是非常轻量级的，对服务器不会有多大开销： // 它都是local zk server在内存中处理 // 但如果一个path的watcher很多，那么这个O(n)循环 for watcher = range watchers &#123; w.process(event) &#125; &#125;&#125;func process(WatchedEvent event) &#123; h = new ReplyHeader(-1, -1L, 0) sendResponse(h, event) // if IOException, close the client conn // sock.write(非阻塞) async write // sendResponse对同一个client是串行的，顺序的&#125; 顺序123456client.get(path, watch=true)// 此时数据发生变化zk保证的顺序：client先拿到watch event，之后才能看到最新的数据client如果watch很多时间，那么得到这些event的顺序与server端发生的顺序是完全一致的 watch的保持zk client连接zk1, 并get with watch，突然zk1 crash，client连接到zk2，那么watch是如何保持的?这是client端实现的，内存里记录watches，在pick new server后，sendSetWatches watch的事件会丢吗client2能获取到每次的set事件吗?12client1不停地set(node, newValue)client2 get with watch 不一定：因为是one time trigger获取event后，要重新watch，在此过程中可能产生新的事件: 期间事件lost 此外，zk与client的conn断开后，client会连接下一个zk，在此期间的事件lost例如，watch NodeCreated事件，在client重新连接期间，该node created，那么client将永远无法获取该事件 watch同一个znode多次，会收到几条event?由于WatchManager的实现，相同类型的watch在一个path上被set多次，只会触发一次 12create(&quot;/foo&quot;, EPHEMERAL_SEQUENTIAL)exists(&quot;/foo&quot;, watcher) // 那么这个watch事件是永远不会trigger的，因为path不同，见WatchManager的实现 ClientrecvLoop里任意的错误，都会pick next server and authentication，进入新的循环 conn reset by peer conn EOF receive packet timeout session expire time conn.recvTimeout = sessionTimeout * 2 / 3 ping interval = sessionTimeout / 3 例如，sessionTimeout=30s，那么client在等待20s还得不到response，就会try next server恰好赶在ping的窗口期 10+20=30 Q/Aclient ping是如何保持住session的?client连接s1，定期ping，但s1 crash后client连接s2，为什么session能保持住?123456connect(s2)send(ConnectRequest&#123;LastZxidSeen, SessionID&#125;) // SessionID是s1当时分配的var r ConnectResponse = recv()if r.SessionID == 0 &#123; // session expire&#125; createSession会通过txn，因此client可以failoverserver在sessionTimeout内没有收到ping，就会closeSession，它也通过txn session idzk session id assigned by server, global unique 123456func initializeNextSession(id=1) &#123; long nextSid = 0; nextSid = (System.currentTimeMillis() &lt;&lt; 24) &gt;&gt;&gt; 8; nextSid = nextSid | (id &lt;&lt;56); return nextSid;&#125; 后面的session id就是这个种子基础上 increment by 1 Edge casesleader electionLOOKING后，把自己的zxid广播，是得到大多数同意就成为leader?是，不需要等全部ack async commit[S1(leader), S2, S3]S1 Propose set(a)=5，在得到majority Ack(proposal)后，向所有机器发送Commit，Q1. S1需要在得到majority Ack(commit)后才return OK to client?Q2. 如果S1发送Commit给所有机器前恰好挂了，new leader会恢复这个事务吗？ leader在得到majority Ack(proposal)后，majority servers已经记录下了txnlog，leader发送Commit只是为了让serversmake the txn visibile to client，Commit消息是不会记录txnlog的leader处理Commit是异步的，不需要等待Commit的ack，即Q1: no，Q2: yes ZAB makes the guarantee that a proposal which has been logged by a quorum of followers will eventually be committedany uncommited proposals from a previous epoch seen by a new leader will be committed by that leader before it becomes active. 换个角度看这个问题：S1得到请求set(a)=5，commit locally，但commit还没有发送给S2，S3，crash!这时候，一个client可能发请求 get(a)，如果它连接的是S1，在S1 crash前，get(a)=2所以，这个commit必须让新leader知道 sync proposal[S1(leader), S2, S3, S4, S5]S1 Propose set(a)=2，发送给了S2 Proposal，但S3-5还没有收到Proposal，此时S1 crash，那么这个proposal在new leader上会被恢复吗? 即重新选举后，get(a)=2? 不一定！ 1234567S1(leader), S2, S3, S4, S5现在propose set(a)=b，S1确认了，但其他还没有确认，此时全部crash然后启动S2-S5，等一会儿再启动S1，那么S2-S5他们的txid相同，会选出S5 leader等S1启动时，它的txid是最大的，a=b可能会丢：如果S1启动慢了200ms内，可能不会丢；否则，例如慢了1分钟，则丢了，S1变成follower后会把该txid truncate: txnlog seek FastLeaderElection.java123456789101112131415161718192021222324252627282930finalizeWait=200ms // 在得到majority确认后，但还没有得到全部确认，wait before make leadersendNotifications()for i.am.looking &#123; n = recvqueue.poll() switch n.state &#123; case LOOKING: compare my proposal with n and update my proposal if every node agrees &#123; // got the leader! return &#125; if quorum agrees &#123; // Verify if there is any change in the proposed leader for &#123; n = recvqueue.poll(200ms) if n == nil &#123; break &#125; &#125; &#125; case FOLLOWING, LEADING: if leader is not me &#123; // confirm I have recv notification from leader // stating that he is leader &#125; &#125;&#125; Referenceshttps://issues.apache.org/jira/browse/ZOOKEEPER-1813https://issues.apache.org/jira/browse/ZOOKEEPER-417","categories":[],"tags":[{"name":"一致性","slug":"一致性","permalink":"http://funkygao.github.io/tags/一致性/"}]},{"title":"delay and schedule message delivery","slug":"delay-and-schedule-message-delivery","date":"2017-05-15T00:11:24.000Z","updated":"2017-05-15T00:26:43.000Z","comments":true,"path":"2017/05/15/delay-and-schedule-message-delivery/","link":"","permalink":"http://funkygao.github.io/2017/05/15/delay-and-schedule-message-delivery/","excerpt":"","keywords":[],"text":"使用场景 业务需要 通过它可以实现XA的prepare/commit/rollback，从而实现与其他系统的原子提交 实现kateway通过mysql作为WAL，并通过background worker(actor)来实现调度/commit/rollback 优先队列以message due time作为优先级进行存储，配合workermessage rollback可以通过发送一个tombstone message实现但由于worker的async，无法在rollback时判断是否真正rollback成功：一条消息要5分钟后发送，在5分钟到达时，client可能恰好要取消，这时候，rollback与worker之间存在race condition，需要正常处理这个一致性：要么，取消失败，消息被发出要么，取消成功，消息不发出不能，取消成功，消息被发出1234567891011// workerfor &#123; if msg := peek(queue); msg.due() &#123; msg = pop(queue) if msg.isTombstone() &#123; // the msg is cancelled &#125; else &#123; publish(msg) &#125; &#125;&#125;","categories":[],"tags":[{"name":"PubSub","slug":"PubSub","permalink":"http://funkygao.github.io/tags/PubSub/"}]},{"title":"mysql repeatable read write skew","slug":"repeatable-read-write-skew","date":"2017-05-12T01:18:24.000Z","updated":"2017-05-15T09:25:14.000Z","comments":true,"path":"2017/05/12/repeatable-read-write-skew/","link":"","permalink":"http://funkygao.github.io/2017/05/12/repeatable-read-write-skew/","excerpt":"","keywords":[],"text":"Isolation教科书里的4种isolation read uncommitted: 即dirty read，可能读到其他rollback的数据 read committed: 即non-repeatable read，同一个txn内读一条数据多次，结果可能不同 repeatable read: 一个txn内读一条数据多次结果相同，但不保证读多个数据的时候也相同(phantom read) serialized 但它只是从锁的实现来描述的，不适用于MVCC。各个数据库产品，虽然采用了这些isolation名字，但语义各不相同，很多与教科书里的定义不符 MySQL不会出现phantom read。MySQL里的RR其实是Snapshot Isolation，只有Serialized是完全基于锁 PostgreSQL实际上只有2个隔离级别：Read Committed和Serialized而Serialized是基于MVCC的无锁实现，即Serialized Snapshot MVCC Snapshot存在write skew问题 甲在一个银行有两张信用卡，分别是A和B。银行给这两张卡总的信用额度是2000，即A透支的额度和B透支的额度相加必须不大于2000：A+B&lt;=2000。 A账号扣款1234567begin;a = select credit from ab = select credit from bif (a + b) + amount &lt;= 2000 &#123; update a set credit = credit + amount&#125;commit B账号扣款1234567begin;a = select credit from ab = select credit from bif (a + b) + amount &lt;= 2000 &#123; update b set credit = credit + amount&#125;commit 假设现在credit(a)=1000, credit(b)=500, 1500&lt;=2000甲同时用a账号消费400，b账号消费300在mysql RR下，2个事务都成功，但2个事务结束后credit(a)=1400, credit(b)=700, 2100&gt;2000 如果是serialized隔离级别，则没有问题：一个事务会失败 在mysql RR下，可以通过应用层加约束来避免write skew 结论for mysql不能期望加了一个事务就万事大吉，而要了解每种隔离级别的语义。 涉及单行数据事务的话，只要 Read Committed ＋ 乐观锁就足够保证不丢写 涉及多行数据的事务的话，Serializable 隔离环境的话不会出错，但是你不会开 如果开 Repeatable Read （Snapshot）隔离级别，那么可能会因为 Write Skew 而丢掉写 如果是金融业务，尽量不要用MySQL","categories":[],"tags":[{"name":"database","slug":"database","permalink":"http://funkygao.github.io/tags/database/"}]},{"title":"dual write conflict","slug":"dual-write-conflict","date":"2017-05-11T23:58:30.000Z","updated":"2017-05-27T02:39:14.000Z","comments":true,"path":"2017/05/12/dual-write-conflict/","link":"","permalink":"http://funkygao.github.io/2017/05/12/dual-write-conflict/","excerpt":"","keywords":[],"text":"","categories":[],"tags":[{"name":"一致性","slug":"一致性","permalink":"http://funkygao.github.io/tags/一致性/"}]},{"title":"shard scales","slug":"shard-scales","date":"2017-05-11T23:58:16.000Z","updated":"2017-05-12T00:03:08.000Z","comments":true,"path":"2017/05/12/shard-scales/","link":"","permalink":"http://funkygao.github.io/2017/05/12/shard-scales/","excerpt":"","keywords":[],"text":"","categories":[],"tags":[{"name":"sharding","slug":"sharding","permalink":"http://funkygao.github.io/tags/sharding/"}]},{"title":"mysql group replication","slug":"mysql-group-replication","date":"2017-05-11T08:50:06.000Z","updated":"2017-05-15T02:12:36.000Z","comments":true,"path":"2017/05/11/mysql-group-replication/","link":"","permalink":"http://funkygao.github.io/2017/05/11/mysql-group-replication/","excerpt":"","keywords":[],"text":"简介GR是个mysql插件，通过原子广播协议、乐观事务冲突检测实现了高可用的多master集群每个master都有全量数据，client side load balance write workload或者使用ProxySQL读事务都是本地执行的有2种模式 单主，自动选主 多主，active active master 与PXC是完全的竞争产品 Requirements and Limitations InnoDB engine only, rollback uncommitted changes turn on binlog RBR GTID enabled each table MUST have a primary key或者not null unique key no concurrent DDL 至少3台master，至多9台，不需要slave auto_increment字段通过offset把各个master隔离开，避免冲突 cascading foreign key not supported 只是校验write set，serializable isolation NOT supported 存在stale read问题，如果write/read不在一台member savepoints可能有问题 Performancehttp://mysqlhighavailability.com/an-overview-of-the-group-replication-performance/ 80% throughput of a standalone MySQL server Internals XCOMeXtended COMmunications，一个Paxos系统 确保消息在所有member上相同顺序分发 动态成员，成员失效检测 理论基础 Database State Machine 事务的Update操作都在一个成员上执行，在Commit时把write-set以total order发送消息给每个成员；每个成员上的certification进程检查事务冲突(first commit wins)，完成最终提交或回滚 Commit时的Paxos有2个作用 certification，检测事务冲突 propagate Group Replication ensures that a transaction only commits after a majority of the members in a group have received itand agreed on the relative order between all transactions that were sent concurrently. 与multi-paxos不同，XCOM是multi-leader/multi-proposer：每个member都是leader of its own slots Certificationgroup_replication_group_name就是GTID里的UUIDGTID就是database versionmysql&gt; select @@global.gtid_executed transaction write set: [{updated_row_pk: GTID_EXECUTED}, {updated_row_pk: GTID_EXECUTED}, …] GTID是由certification模块负责的，由它来负责GTID GNO的increment所有member会定期交换GTID_EXECUTED，所有member已经committed事务的交集：Stable Set. Transaction Distributed Recovery向group增加新成员的过程: 获取missing data，同时cache正在发生的新事务，最后catch up 123456789101112131415161718192021222324252627282930// 从现有member里通过mysql backup工具(mysqldump等)搞个backup instance// phase 0: joinJoiner.join(), 通过total order broadcast发给每个member生成view change binlog event: $viewIDgroup里每个member(包括Joiner)都会收到该view event每个online member会把该binlog event排队到现有transaction queue里// phase 1: row copyJoiner pick a live member from the group as Donor // Donor可能会有lagDoner transmits all data up to the joining moment: master/slave connectionfor &#123; if binlog.event.view_id == $viewID &#123; Joiner.SQLThread.stop() break &#125; if Doner.dies &#123; reselect Donner goto restart &#125;&#125;// phase 2: catch upjoining moment后发生的binlogDonor发给Joiner，Joiner applycatch up同步完成后，declare Joiner online，开始对外服务// Joiner.leave()类似的过程// crash过程会被detector发现，自动执行Joiner.leave() 这个过程与mysql在线alter table设计原理类似 binlog view change markersgroup里member变化，会产生一种新的binlog event: view change log event.view id就是一种logicl clock，在member变化时inrement123+-----------------+| epoch | counter |+-----------------+ epoch在第一个加入group的member生成，作用是为了解决all members crash问题: avoid dup counter certification based replication通过group communication和total order transaction实现synchronous replication 事务在单节点乐观运行，在commit时，通过广播和冲突检测实现全局数据一致性它需要 transactional database来rollback uncommitted changes primary keys to generate broadcast write-set atomic changes global ordering replication events Config123456789101112131415[mysqld]log-binbinlog-format=rowbinlog-checksum=NONEgtid-mode=ONenforce-gtid-consistencylog-slave-updatesmaster-info-repository=TABLErelay-log-info-repository=TABLEtransaction-write-set-extraction=MURMUR32// GRgroup_replication_group_name=&quot;da7bad5b-daed-da7a-ba44-da7aba5e7ab&quot;group_replication_local_address=&quot;host2:24901&quot;group_replication_group_seeds=&quot;host1:24901,host2:24901,host3:24901&quot; FAQGR是同步还是异步？replication分为5步12345master locally applymaster generate binlog eventmaster sending the event to slave(s)slave IO thread add event to relay logslave SQL thread apply the event from relay log GR下，只有3是同步的: 把write set广播并得到majority certify confirm广播时发送消息是同步的，但apply write set还是异步的:12345678910member1: DELETE FROM a; // a table with many rowsmember1: 产生一个非常大的binlog eventmember1: group communicate the binlog event to all members(包括它自己)其他member确认ok，那么member1就返回ok给clientclient访问member1，那么数据是一致的但其他member在异步apply binlog event，可能花很长时间，这时候client访问member2，可能不一致：delete的数据仍然能读出来 Referenceshttp://lefred.be/content/mysql-group-replication-about-ack-from-majority/http://lefred.be/content/mysql-group-replication-synchronous-or-asynchronous-replication/http://lefred.be/content/galera-replication-demystified-how-does-it-work/http://www.tocker.ca/2014/12/30/an-easy-way-to-describe-mysqls-binary-log-group-commit.htmlhttp://mysqlhighavailability.com/tag/mysql-group-replication/http://mysqlhighavailability.com/mysql-group-replication-transaction-life-cycle-explained/","categories":[],"tags":[{"name":"database","slug":"database","permalink":"http://funkygao.github.io/tags/database/"}]},{"title":"mysql在线alter table设计","slug":"osc","date":"2017-05-11T07:42:46.000Z","updated":"2017-05-12T00:59:38.000Z","comments":true,"path":"2017/05/11/osc/","link":"","permalink":"http://funkygao.github.io/2017/05/11/osc/","excerpt":"","keywords":[],"text":"主要逻辑1234567891011121314151617181920212223// 合法性检查// 包括：是否有外键、用户权限、表是否合法、是否有唯一键等// 创建变更记录表CREATE /* changelog table */ TABLE _tbs_c// 创建影子表CREATE /* shadow table */ TABLE _tbl_s LIKE tbl// 在影子表上应用alter语句ALTER TABLE _tbl_s STATEMENT// 开始行拷贝线程 tbl -&gt; _tbl_s// 开始binlog接收和应用线程 binlog -&gt; _tbl_s// 等待行拷贝线程完成// 通知binlog线程收工// 等待binlog线程结束// 开始切换LOCK TABLES tbl WRITERENAME TABLE tbl TO _tbl_old, _tbl_s TO tbl UNLOCK TABLES 确定行拷贝chunk范围123select id from (select id from a where id&gt;=0 and id&lt;=3001 order by id asc limit 1000) select_osc_chunk order by id desc limit 1; 行拷贝in chunk1234567begin;insert ignore into `a`.`_a_gho` (`id`, `value`) (select `id`, `value` from `a`.`a` force index (`PRIMARY`) where (((`id` &gt; ?) or ((`id` = ?))) and ((`id` &lt; ?) or ((`id` = ?)))) lock in share mode )commit; 关键点async binlog worker如何判断所有数据变更已经完成binlog worker向changelog table发一行记录，在收到这个记录时，即表示完成 RENAME race condition with DMLmysql内部保证，LOCK TABLE后，如果有DML与RENAME并发操作，那么在UNLOCK TABLES时，RENAME一定获取最高优先级，即：RENAME一定会先执行。否则，会丢数据:1234567LOCK TABLE WRITEINSERT // blockedRENAME // blockedUNLOCK TABLEINERT // 如果INSERT先执行，那么它会插入原表RENAME // 原表被rename to tbl_old，刚才INSERT的数据丢失: 存放在了tbl_old LOCK, RENAME如果在一个mysql连接内执行LOCK; RENAME，那么会失败解决办法：创建2个mysql连接，分别执行LOCK和RENAME","categories":[],"tags":[{"name":"database","slug":"database","permalink":"http://funkygao.github.io/tags/database/"}]},{"title":"两段锁 2PL","slug":"2PL","date":"2017-05-11T07:33:41.000Z","updated":"2017-05-16T08:51:42.000Z","comments":true,"path":"2017/05/11/2PL/","link":"","permalink":"http://funkygao.github.io/2017/05/11/2PL/","excerpt":"","keywords":[],"text":"事务开始后就处于加锁阶段，一直到执行ROLLBACK和COMMIT之前都是加锁阶段。ROLLBACK和COMMIT使事务进入解锁阶段 事务遵守两段锁协议是可串行化调度的充分条件，而不是必要条件 MS SQL Server默认采用2PL实现isolation，Oralce/PostgreSQL/MySQL InnoDB默认使用MVCC MySQL 2PL提供2种锁 shared(read) exclusive(write) 读写互斥，但读读不互斥 MySQL serialized isolation","categories":[],"tags":[{"name":"database","slug":"database","permalink":"http://funkygao.github.io/tags/database/"}]}]}